\PassOptionsToPackage{xetex}{xcolor}
\PassOptionsToPackage{xetex}{graphicx}
\documentclass[a4paper,landscape,headrule,footrule,xetex]{foils}

\input{headx.tex}
\usepackage{bibentry}
\renewcommand{\cite}{\bibentry}

\header{Lecture 11}{Representativeness and Balance}{}

\usepackage{pst-node}
\newcommand{\sa}[2]{\rnode{c#1}{\iz{#2}}}%\nodebox{c#1}}

%\usepackage{hieroglf}
\usepackage{wasysym}
%\newcommand{\grn}[1]{\textcolor{PineGreen}{#1}}
\newcommand{\ont}[1]{\textcolor{blue}{#1}}
\newcommand{\jcy}[1]{\textcolor{orange}{#1}}
\newcommand{\lxd}[1]{\textcolor{brown}{#1}}


\newcommand{\psp}[1]{\textcolor{purple}{#1}}
\newcommand{\dtr}[1]{\textcolor{blue}{#1}}
\newcommand{\nam}[1]{\textcolor{blue}{#1}}
\newcommand{\idm}[1]{\textcolor{brown}{#1}}
\newcommand{\gen}[1]{\textcolor{orange}{#1}}
\newcommand{\exl}[1]{\textcolor{orange}{#1}}
\newcommand{\trg}[1]{\textcolor{red}{#1}}


\newcommand{\hinoki}{\grn{Hinoki}\xspace}
\newcommand{\lexeed}{\lxd{Lexeed}\xspace}
\newcommand{\jacy}{\jcy{JACY}\xspace}
\newcommand{\onto}{\ont{Ontology}\xspace}
%\newcommand{\itsdb}{\textsf{[incr tsdb()]}\xspace}
\newcommand{\GT}{Goi-Taikei\xspace}


\begin{document}
\bibliographystyle{apalike}
\nobibliography{abb,mtg,nlp,ling}
\maketitle


\myslide{Overview}

\begin{itemize} 
\item Revision of Corpora and Language Engineering
  \begin{itemize}
  \item Language as a Statistical Model
  \item NLP and the Empirical Revolution
  \item The Empirical Revolution and Linguistics
  \end{itemize}
\item Representativeness and balance
\item Copyright and Ethics
\end{itemize}
%%% 
%%% this changes each year, so keep separate
%%%

%%
%%% FIXME: Summarize
%%%

\section{Review}


%%%
%%% Evaluation and the Empirical Revolution
%%%
\myslide{Testing and Training}

\begin{itemize}
\item Language Engineering use Corpora in two important ways:
  \begin{itemize}
  \item Testing
    \begin{itemize}
    \item Create a \blu{reference set} or \blu{gold standard}
    \item Test how well a system can produce these results
    \end{itemize}
  \item Training
   \begin{itemize}
    \item Create a collection of \blu{labeled examples}
    \item Use these to learn features to classify new examples with
      one of the labels
    \end{itemize}

  \item Models are implicit in the corpus, rather than written by hand
  \item Even which features are useful can be learned
  \item Annotation becomes the bottleneck
  \end{itemize}
\end{itemize}

\myslide{The need for automatic testing}
\MyLogo{}
\begin{itemize}
\item As systems get bigger, behavior is harder to predict
\item Looking at system output one sentence at a time is slow

\item Can we automate testing?
  \begin{enumerate}
  \item Create a gold standard or reference (the \blu{right} answer)
  \item Compare your result to the reference
  \item Measure the error
  \item Attempt to minimize it \blu{globally} (over a large test set)
    \begin{itemize}
    \item \textit{the plural of anecdote is not data}
    \item intuition tends to miss many examples of use
    \end{itemize}
  \end{enumerate} 

\end{itemize}

\myslide{The Empirical approach}

\begin{enumerate}
\item Develop an algorithm and gather examples/rules from \blu{training data}
\item Optimize any parameters on \blu{development data}
  \begin{itemize}
  \item Normally about 10\% of the training data
  \end{itemize}
\item Test on held-out, unseen \blu{test data}
\end{enumerate}

This gives a fair estimate of how good the algorithm is 
\\ --- if the test criteria are appropriate.


\myslide{Empirical vs Rational NLP}
  \begin{itemize}
  \item The 1990s went through an empirical revolution
  \item Funding agencies sponsored competitions
    \begin{itemize}
    \item TREC: Text REtrieval Conference
    \item MUC: Message Understanding Conference
    \item DARPA Machine Translation Competitions
    \end{itemize}
  \item Data to test with became more available
  \item Reviewers demanded evaluation in papers
  \item A lot of research on evaluation methods
  \end{itemize}

\myslide{Problems with testing}


\begin{itemize}
\item {\large You get better at what you test}
\item If the metric is not the actual goal things go wrong
  \begin{itemize}
  \item  BLEU score originally correlated with human judgement
  \item As systems optimized for BLEU
  \item \ldots they lost the correlation
  \item You can  improve the metric, not the goal
  \end{itemize}
\item The solution is better metrics, but that is hard for MT
\item We need to test for similar meaning: a very hard problem
\end{itemize}



\myslide{Conclusions}
\begin{itemize}
\item A surprising amount of variation is possible in MT
\item This makes evaluation difficult
  \begin{itemize}
  \item If we know \blu{a} correct answer, the problem is still not solved
  \end{itemize}
\item But evaluation is very important in NLP
  \begin{itemize}
  \item Use automatic evaluation
  \item Recognize the risks
  \end{itemize}
\item The closer the training is to the test, the better the result
\item The general conclusion: \blu{more data is better data}
\end{itemize}

\section{Representativeness and Balance}
\MyLogo{}
This section is based on: ``Corpus and Text: Basic Principles'' by
John Sinclair (2004) in \textit{Developing Linguistic Corpora: a Guide
  to Good Practice} Martin Wynne ed, University of Oxford

\myslide{Representativeness}

To define \blu{representativeness} we need to consider the following questions about the users of the language we will represent:

\begin{itemize}
\item  What sort of documents do they write and read, and what sort of spoken encounters do they have?
\item How can we allow for the relative popularity of some publications over others, and the difference in attention given to different publications?
\item How do we allow for the unavoidable influence of practicalities such as the relative ease of acquiring public printed language, e-mails and web pages as compared with the labour and expense of recording and transcribing private conversations or acquiring and keying personal handwritten correspondence?
\item How do we identify the instances of language that are influential as models for the population, and therefore might be weighted more heavily than the rest?
\end{itemize}

There are no definite answers to these questions.

\myslide{How to be representative}

\begin{enumerate}
\item \blu{decide on the structural criteria} that you will use to build the corpus, and apply them to create a framework for the principal corpus components;
\item for each component \blu{draw up a comprehensive inventory} of text types that are found there, \blu{using external criteria} only;
\item \blu{put the text types in a priority order}, taking into account all the factors that you think might increase or decrease the importance of a text type — the kind of factors discussed above;
\item \blu{estimate a target size} for each text type, relating together (i) the overall target size for the component (ii) the number of text types (iii) the importance of each (iv) the practicality of gathering quantities of it;
\item as the corpus takes shape, maintain comparison between the actual dimensions of the material and the original plan;
\item (most important of all) \blu{document these steps} so that users can have a reference point if they get unexpected results, and that improvements can be made on the basis of experience.
\end{enumerate}

% Let me give one simple example of these precepts in operation. The precursor of The Bank of English contained a substantial proportion of the quality fiction of the day. This came from a request from one of the sponsors, who felt that a corpus was such an odd thing (in 1980 it was an odd thing) that users of the end products would be reassured if there was quite a lot of "good writing" in it. That is to say, under (a) above it was decided that there should be emphasis on this kind of writing; this decision affected the choice of texts under (b) also. However, one of the main aims of creating the corpus was to retrieve evidence in support of the learning of the English language, and the requirements of this mundane purpose clashed with some of the prominent features of modern fiction. For example, the broad range of verbs used to introduce speech in novels came out rather too strongly — wail, bark and grin are all attested in this grammatical function, and while their occurrence is of interest to students of literary style, they are of limited utility to learners seeking basic fluency in English (Sinclair et. al. 1990 p. 318).

% This clash between the design of the corpus and its function became clear as soon as work started on the first Cobuild grammar (1990). Because the corpus had been carefully designed and fully documented, it was possible to determine — and therefore roughly counterbalance — the bias that had been introduced. In fairness to the original designers, it should be emphasised that there were no previous models to turn to at that time, and no way of assessing the effects of different varieties of a language.

% A corpus that sets out to represent a language or a variety of a language cannot predict what queries will be made of it, so users must be able to refer to its make-up in order to interpret results accurately. In everything to do with criteria, this point about documentation is crucial. So many of our decisions are subjective that it is essential that a user can inspect not only the contents of a corpus but the reasons that the contents are as they are. Sociolinguistics is extremely fashion-conscious, and arguments that are acceptable criteria during one decade may look very old-fashioned in the next.

% Also at any time a researcher may get strange results, counter-intuitive and conflicting with established descriptions. Neither of these factors proves that there is something wrong with the corpus, because corpora are full of surprises, but they do cast doubt on the interpretation of the findings, and one of the researcher's first moves on encountering unexpected results will be to check that there is not something in the corpus architecture or the selection of texts that might account for it.

\begin{quotation}
  \textit{The design and composition of a corpus should be documented fully
  with information about the contents and arguments in justification
  of the decisions taken.}
\end{quotation}

\myslide{Balance}

\begin{itemize}
\item for a corpus to be  balanced, the proportions of different kinds of text it contains should correspond with informed and intuitive judgments.
\item Most general corpora of today are biased towards text: estimates of the optimal proportion of spoken language range from 50\% to 90\%
\\ because speech  is so expensive to collect this imbalance is likely to remain.
\item Balance can conflict with representativeness
  \begin{itemize}
  \item Consider popular magazines in English
  \item  there are a large number of them and most use a highly specialised language
  \item It is an important text type, but it is almost impossible to select a few texts which can claim to be representative
  \item Can magazines for fly fishermen, personal computers and popular music really represent the whole variety of popular magazines (as is the case in The Bank of English)?
  \end{itemize}
\item Specialised corpora are constructed after some initial
  selectional criteria have been applied, for example a blog corpus or
  a patent corpus. More delicate criteria are used to partition them,
  but the issues of balance and representativeness remain cogent and
  central in the design.
\end{itemize}

\begin{quotation}
  \textit{The corpus builder should retain, as target notions,
    representativeness and balance. While these are not precisely
    definable and attainable goals, they must be used to guide the
    design of a corpus and the selection of its components.}
\end{quotation}

\myslide{Summary}

\begin{itemize}
\item The extent to which conclusions from a test can be generalized
  depend on both the nature of the evaluation function and the size
  and representativeness of the test set
\item The extent to which conclusions drawn from a corpus study can be
  generalized to all language depend crucially on the design of
  the corpus
\item In general \blu{more \textbf{representative} data is better data}
\item But we need to be aware of limitations:
  \begin{itemize}
  \item Data sparsity
  \item Out of vocabulary items
  \item Over fitting
  \item Domain adaption
  \end{itemize}
\end{itemize}


\section{Copyright and Licensing}

\myslide{Copyright}
\MyLogo{I am not a lawyer}
\begin{itemize}
\item Governments grant certain rights to authors of creative works,
  typically called \blu{copyrights} in order encourage them
  to produce more
  \begin{itemize}
  \item The most basic right is the right to forbid people from
    copying it without permission
  \item Any work produced is by default copyright of the author
  \end{itemize}
\item Some or all of these rights can be waived or transferred
  \begin{itemize}
  \item An author may sell the rights for a manuscript to a publisher
  \item A blogger may place their postings in the public domain
  \item A publisher may give permission to an author to post their
    paper on their website
  \item A work may be distributed under a license that allows copying only under some conditions
  \end{itemize}
\newpage
\item Copyright laws are national laws, although they may be
  harmonized by treaties
  \begin{itemize}
  \item A text may be illegal to copy in one country, but legal in another
  \end{itemize}
\item Copyright laws change over time
  \begin{itemize}
  \item E.g. in the U.S. originally 14 years for books only
  \item Now 70 years after the death of the author for almost
    everything \\ (but not recipes)
  \end{itemize}
\item New technology complicates things
  \begin{itemize}
  \item Sending email involves making multiple copies on different servers
  \item Recording speech can happen without the creator's knowledge
  \end{itemize}
\end{itemize}

\begin{center}
  \emp{Copyright issues are very complicated}
\end{center}

\myslide{Some Rough Guidelines}

\begin{itemize}
\item Copying something which is under copyright is \blu{illegal} unless
  specific permission is granted or it falls under \textbf{fair
    dealing}, such as for the purpose of research or education
\item How can you get permission?
  \begin{itemize}
  \item You can buy it (for some works)
  \item You can get signed permission from the copyright holder
\\ (or recorded permission for preliterate speakers)
  \item You can get implicit permission (e.g. for email or web pages)
  \item It can be permitted by a license
    \begin{itemize}
    \item \txx{CC-by} allows you to copy and redistribute if you acknowledge
    \item \txx{CC-by-nconc} allows you to copy and redistribute if you
      acknowledge and it is for non-commercial use
    \end{itemize}
  \end{itemize}

\newpage \lurl{http://en.wikipedia.org/wiki/Fair_dealing}
\item The following factors will be considered to decide if it is fair
  dealing (in Singapore)
  \begin{itemize}
  \item  purpose and character of the dealing, including whether such dealing is of a commercial nature or is for non-profit educational purposes
  \item  nature of the work or adaptation
  \item amount copied, relative to the whole work
  \item  effect of the dealing upon the potential market for the work, and effect upon its value
  \item the possibility of obtaining the work or adaptation within a reasonable time at an ordinary commercial price
  \item whether the copy is for the purpose of criticism or review; for the purpose reporting of news; for the purpose of judicial proceedings or professional advice (a sufficient acknowledgment of the work is required)
  \item it is not an infringement if a person makes a copy from an
    original copy of a computer program  as a back-up
  \end{itemize}
\end{itemize}

\myslide{Copyright for Corpora}
\MyLogo{}
\begin{itemize}
\item Arguments for \blu{restrictive licensing}
  \begin{itemize}
  \item Competitive advantage (common for speech corpora)
  \item Compensation for the effort of creation
  \item Minimize effect on the value of the original work
  \end{itemize}
\item Arguments for \blu{open licensing}
  \begin{itemize}
  \item Annotation is expensive, making the data open gets the best
    return on this investment
  \item Annotation is typically ongoing, opening the data gets you
    more feedback
 \item Researchers are evaluated by the impact that their work has.
   Open data generally has more impact.
  \item Language data is part of our shared heritage
  \end{itemize}
\end{itemize}

\myslide{Choice of License}
\begin{itemize}
\item Should be considered early on (before you start compiling your corpus)
\item May depend on the funding body
\item Depends on the source data
\item General trend is to open licensing
  \begin{itemize}
  \item Open Science Project
  \item Open Access Journals
  \item Open Source Software
  \end{itemize}
\item Try to chose a standard license (such as Creative Commons)
\end{itemize}
\myslide{NTU's policy on Data Sharing}
\begin{itemize}
\item[5.6.1]  ``The final research data from projects carried out
  at NTU shall be made available for sharing (via the NTU Data
  Repository) unless there are prior formal agreements with external
  collaborators and parties on non-disclosure or proprietary use of
  the data.''  \url{http://research.ntu.edu.sg/rieo/RI/Pages/Research-Data-Policies.aspx}
\item[5.6.2]  ``The sharing and use of research data shall be based on Creative Commons license CC:BY:NC, where others may use data for non-commercial applications only and must correctly attribute the data source in NTU.''

\end{itemize}

\myslide{Creative Commons Licenses}
\lurl{http://creativecommons.org/licenses/}
\medskip
\begin{tabular}{lccc}
  License       & Derivative Works & Same License & Commercial Use \\
\hline
  CC-BY         &   + &  - &  + \\
  CC-BY-SA      &   + &  + &  + \\  
  CC-BY-NC      &   + &  - &  - \\
  CC-BY-ND      &   - &  - &  + \\
  CC-BY-NC-SA   &   + &  + &  - \\
  CC-BY-NC-ND   &   - &  - &  - \\
\end{tabular}
\begin{description} \addtolength{\itemsep}{-0.5\itemsep}
\item[BY] Attribution (all licenses)
\item[SA] Share Alike (requires copies to have the same license)
\item[NC] Non-Commercial
    \com{\href{https://opendefinition.org/}{Not Open}}
\item[ND] No Derivatives (allows only exact copies) 
  \com{\href{https://opendefinition.org/}{Not Open}}
\end{description}

Many, many other license also exist (GPL, MIT, BSD, Apache, \ldots)

 \myslide{The Open Definition}
\MyLogo{https://opendefinition.org/}
 \begin{itemize}
 \item The Open Definition sets out principles that define \txx{openness}
   in relation to data and content.
 \item It makes precise the meaning of \txx{open} in the terms \txx{open data}
   and \txx{open content} and thereby ensures quality and encourages
   compatibility between different pools of open material.
 \item It can be summed up in the statement that:
   \begin{quote}
     “Open means anyone can freely access, use, modify, and share for
     any purpose (subject, at most, to requirements that preserve
     provenance and openness).”
   \end{quote}
 \item Put most succinctly:
   \begin{quote}
     “Open data and content can be freely used, modified, and shared
     by anyone for any purpose”
   \end{quote}
 \end{itemize}

 
\myslide{Conclusions}

\begin{center}
  Be careful of copyright
\end{center}

% \myslide{Acknowledgments}
%  \MyLogo{HG351 (2011)}

%  \begin{itemize}
%  \item Historical Linguist examples taken from Chapter 4 of
%    \bibentry{Biber:Conrad:Reppen:1998}
%  \item Several papers from Richard Xiao, Lianzhen He, and Ming Yue
%    (2008) \textit{Proceedings of The International Symposium on Using
%      Corpora in Contrastive and Translation Studies (UCCTS 2008)}, Alberta
% \\ \url{www.lancs.ac.uk/fass/projects/corpus/UCCTS2008Proceedings/}
%  \end{itemize}
% \item Thanks to Stefan Th. Gries (University of California, Santa
%    Barbara) for his great introduction \textit{Useful statistics for
%      corpus linguistics} \url{http://www.linguistics.ucsb.edu/faculty/stgries/research/UsefulStatsForCorpLing.pdf}
%  \item Some examples taken from Ted Dunning's \textit{Surprise and
%      Coincidence - musings from the long tail}
%    \url{http://tdunning.blogspot.com/2008/03/surprise-and-coincidence.html}

%   inspiration for some of the slides (from  \textit{LING 2050 Special Topics in Linguistics: Corpus linguistics}, U Penn).
% \item Thanks to Sandra K\"{u}bler for some of the slides from her 
% \textit{RoCoLi\footnote{Romania Computational Linguistics Summer School} Course: Computational Tools for Corpus Linguistics}
% %\item Thanks to Mark Davies (BYU) for the exploration ideas.
% \item Definitions from WordNet 3.0
% \end{itemize}

\end{document}


%%% Local Variables: 
%%% coding: utf-8
%%% mode: latex
%%% TeX-PDF-mode: t
%%% TeX-engine: xetex
%%% LaTeX-section-list:  (("myslide" 1))
%%% End: 
